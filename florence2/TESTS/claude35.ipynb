{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import shutil\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "# Utility function to extract images from PDF pages\n",
    "def extract_pages_as_images(pdf_path, output_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_number in range(len(doc)):\n",
    "        page = doc.load_page(page_number)\n",
    "        image_list = page.get_images(full=True)\n",
    "        \n",
    "        for image_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"{output_folder}/page_{page_number + 1}_image_{image_index + 1}.{image_ext}\"\n",
    "            with open(image_filename, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "\n",
    "# Utility function to encode an image in base64 format\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Main function to process PDF and perform OCR using GPT-4 Vision\n",
    "def process_pdf_with_gpt_vision(pdf_path, output_folder, api_key, gpt_model=\"gpt-4-vision\", verbose=False):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Extract images from the PDF\n",
    "    extract_pages_as_images(pdf_path, output_folder)\n",
    "\n",
    "    # Get the list of images\n",
    "    image_files = [os.path.join(output_folder, file) for file in os.listdir(output_folder) if file.endswith((\"png\", \"jpg\", \"jpeg\"))]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Extracted {len(image_files)} images from the PDF\")\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "    }\n",
    "\n",
    "    # Define the default prompt\n",
    "    prompt = \"Extract the text and data as structured JSON from this image.\"\n",
    "\n",
    "    # Process each image with GPT-4 Vision\n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        if verbose:\n",
    "            print(f\"Processing image {idx + 1} of {len(image_files)}: {image_file}\")\n",
    "\n",
    "        # Encode the image in base64\n",
    "        image_base64 = encode_image_to_base64(image_file)\n",
    "\n",
    "        data = {\n",
    "            \"model\": gpt_model,\n",
    "            \"prompt\": prompt,\n",
    "            \"image\": image_base64,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\"https://api.openai.com/v1/images\", headers=headers, json=data)\n",
    "            result = response.json()\n",
    "\n",
    "            # Save the JSON response\n",
    "            json_output_path = os.path.join(output_folder, f\"image_{idx + 1}_output.json\")\n",
    "            with open(json_output_path, \"w\") as json_file:\n",
    "                json.dump(result, json_file, indent=4)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Output saved: {json_output_path}\")\n",
    "\n",
    "            sleep(5)  # To avoid hitting API rate limits\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {idx + 1}: {e}\")\n",
    "\n",
    "    # Optional: Clean up the image files\n",
    "    shutil.rmtree(output_folder, ignore_errors=True)\n",
    "    if verbose:\n",
    "        print(\"Processing complete. Cleaned up temporary files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 3 images from the PDF\n",
      "Processing image 1 of 3: uploads\\page_1_image_1.png\n",
      "Output saved: uploads\\image_1_output.json\n",
      "Processing image 2 of 3: uploads\\page_1_image_2.png\n",
      "Output saved: uploads\\image_2_output.json\n",
      "Processing image 3 of 3: uploads\\page_2_image_1.png\n",
      "Output saved: uploads\\image_3_output.json\n",
      "Processing complete. Cleaned up temporary files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pdf_path = \"C:\\\\Users\\\\sselva\\\\Downloads\\\\testddoc1.pdf\"\n",
    "output_folder = \"uploads\"\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "process_pdf_with_gpt_vision(pdf_path, output_folder, api_key, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting images from DOCX 'C:\\Users\\sselva\\Downloads\\KO Documents\\KO Documents\\KS100121_Modify eGroup Approver.docx'...\n",
      "Modify eGroup Approver/\n",
      "Administrator/Reviewer\n",
      "\n",
      "Check approval matrix sheet so that we come to know whose approval is required\n",
      "Check the type of eGroup\n",
      "Check for the same in approval matrix sheet so as to whose permission is required\n",
      "Navigate to bst.golder.com  eAdministration  Setup  employee group setup  eGroup Type (eTime or eExpense and Supervisor or Administrator)\n",
      "Find name of that eGroup \n",
      "Click on eGroup name and select it\n",
      "Information will be shown at right side in that update name of Primary or Alternate 1 or Alternate 2 or Alternate 3 as per requirement \n",
      "Click on ‘save’ icon\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from time import sleep\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from transformers.dynamic_module_utils import get_imports\n",
    "from unittest.mock import patch\n",
    "import docx  # For DOCX file processing\n",
    "\n",
    "# Set up device and dtype\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "def load_model_and_processor():\n",
    "    def fixed_get_imports(filename: str | os.PathLike) -> list[str]:\n",
    "        if not str(filename).endswith(\"modeling_florence2.py\"):\n",
    "            return get_imports(filename)\n",
    "        imports = get_imports(filename)\n",
    "        return imports\n",
    "\n",
    "    with patch(\"transformers.dynamic_module_utils.get_imports\", fixed_get_imports):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-base\", torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-base\", trust_remote_code=True)\n",
    "    return model, processor\n",
    "\n",
    "# Utility function to extract images from PDF pages\n",
    "def extract_pages_as_images(pdf_path, output_folder):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_number in range(len(doc)):\n",
    "        page = doc.load_page(page_number)\n",
    "        image_list = page.get_images(full=True)\n",
    "        \n",
    "        for image_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"{output_folder}/page_{page_number + 1}_image_{image_index + 1}.{image_ext}\"\n",
    "            with open(image_filename, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "\n",
    "# Utility function to extract text from DOCX files\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text_content = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text_content.append(paragraph.text)\n",
    "    return \"\\n\".join(text_content)\n",
    "\n",
    "# Main function to process files and perform OCR using Florence 2B\n",
    "def process_file_with_florence(file_path, output_folder, verbose=False):\n",
    "    # Determine file type\n",
    "    file_extension = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    ocr_results = []\n",
    "\n",
    "    if file_extension == \".pdf\":\n",
    "        # Extract images from the PDF\n",
    "        extract_pages_as_images(file_path, output_folder)\n",
    "\n",
    "        # Get the list of images\n",
    "        image_files = [os.path.join(output_folder, file) for file in os.listdir(output_folder) if file.endswith((\"png\", \"jpg\", \"jpeg\"))]\n",
    "\n",
    "        # Define the task prompt for OCR\n",
    "        task_prompt = \"<OCR>\"\n",
    "\n",
    "        # Process each image with the Florence 2B model\n",
    "        for idx, image_file in enumerate(image_files):\n",
    "            if verbose:\n",
    "                print(f\"Processing image {idx + 1} of {len(image_files)}: {image_file}\")\n",
    "\n",
    "            # Load the image\n",
    "            image = Image.open(image_file)\n",
    "\n",
    "            # Run the OCR using the Florence model\n",
    "            result = run_example(image, task_prompt)\n",
    "\n",
    "            # Append the result to the OCR results list\n",
    "            ocr_results.append(result)\n",
    "\n",
    "            # Save the JSON response for each image (optional)\n",
    "            json_output_path = os.path.join(output_folder, f\"image_{idx + 1}_output.json\")\n",
    "            with open(json_output_path, \"w\") as json_file:\n",
    "                json.dump(result, json_file, indent=4)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Output saved: {json_output_path}\")\n",
    "\n",
    "            sleep(5)  # To avoid hitting API rate limits\n",
    "\n",
    "        # Clean up the image files\n",
    "        shutil.rmtree(output_folder, ignore_errors=True)\n",
    "\n",
    "    elif file_extension == \".docx\":\n",
    "        # Extract text from the DOCX file\n",
    "        docx_text = extract_text_from_docx(file_path)\n",
    "        ocr_results.append({\"text\": docx_text})\n",
    "\n",
    "        # Optionally, save the DOCX text to a JSON file\n",
    "        json_output_path = os.path.join(output_folder, \"docx_output.json\")\n",
    "        with open(json_output_path, \"w\") as json_file:\n",
    "            json.dump({\"text\": docx_text}, json_file, indent=4)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Processing complete. Cleaned up temporary files.\")\n",
    "\n",
    "    # Return the consolidated OCR results\n",
    "    return ocr_results\n",
    "\n",
    "# Define the run_example function to utilize the Florence model\n",
    "def run_example(image, task_prompt, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "\n",
    "    model, processor = load_model_and_processor()\n",
    "\n",
    "    if task_prompt == '<OCR>':\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    image = np.array(image)\n",
    "\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to('cpu', torch.float32)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"].cpu(),\n",
    "        pixel_values=inputs[\"pixel_values\"].cpu(),\n",
    "        max_new_tokens=1024,\n",
    "        early_stopping=False,\n",
    "        do_sample=False,\n",
    "        num_beams=3,\n",
    "    )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    print(\"Generated Text:\", generated_text)\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.shape[1], image.shape[0])\n",
    "    )\n",
    "\n",
    "    return parsed_answer\n",
    "\n",
    "# Example usage:\n",
    "# process_file_with_florence(\"your_file.pdf\", \"output_folder\", verbose=True)\n",
    "# process_file_with_florence(\"your_file.docx\", \"output_folder\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Cleaned up temporary files.\n"
     ]
    }
   ],
   "source": [
    "he = process_file_with_florence(\"C:\\\\Users\\\\sselva\\\\Downloads\\\\KO Documents\\\\KO Documents\\\\KS100120_Create or Delete eGroup.docx\",\"uploads\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Create or Delete eGroup\\n\\nCreate eGroup\\nCheck approval matrix sheet so that we come to know whose approval is required\\nIf approval provided, navigate to bst.golder.com\\xa0\\uf0e0\\xa0eAdministration\\xa0\\uf0e0\\xa0Setup\\xa0\\uf0e0\\xa0employee group setup\\xa0\\uf0e0\\xa0eGroup Type(here for eg., eExpense supervisor)\\nClick on eExpense supervisor\\nClick on ‘add’ icon at top of the screen\\nProvide the short name of e-group mentioned in ticket\\nFill in other details like name of e-group (long name of e-group), primary, alt1, alt2, alt3 supervisor names (all provided in the ticket).\\nClick on save. Save button is upward beside add user.\\n\\nDelete eGroup\\nCheck approval matrix sheet so that we come to know whose approval is required \\nCheck the type of eGroup\\nCheck for the same in approval matrix sheet so as to whose permission is required\\nNavigate to bst.golder.com\\xa0\\uf0e0\\xa0eAdministration\\xa0\\uf0e0\\xa0Setup\\xa0\\uf0e0\\xa0employee group setup\\xa0\\uf0e0\\xa0eGroup Type(eTime or eExpense and Supervisor or Administrator)\\nFind name ofthat eGroup \\nClick on eGroup name and select it\\nClick on “Delete” icon\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(he)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
